{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T19:50:12.516753Z",
     "start_time": "2020-11-19T19:50:12.497088Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T19:50:15.369290Z",
     "start_time": "2020-11-19T19:50:15.340458Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T19:50:15.593050Z",
     "start_time": "2020-11-19T19:50:15.572136Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "REPO_DIR = '..' if IN_COLAB  else '..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OD_uoUHdGp5t"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T20:01:09.511494Z",
     "start_time": "2020-11-19T20:01:09.431182Z"
    },
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "8moWllwb-yZr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import collections\n",
    "import tqdm.auto as tqdm\n",
    "import time\n",
    "import gc \n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import sonnet as snt\n",
    "import graph_nets\n",
    "from graph_nets.graphs import GraphsTuple\n",
    "import graph_attribution as gatt\n",
    "\n",
    "# Ignore tf/graph_nets UserWarning:\n",
    "# Converting sparse IndexedSlices to a dense Tensor of unknown shape\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "for mod in [tf, snt, gatt]:\n",
    "    print(f'{mod.__name__:20s} = {mod.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAwhhlmhUWHH"
   },
   "source": [
    "## Graph Attribution specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T19:58:14.416163Z",
     "start_time": "2020-11-19T19:58:14.337198Z"
    }
   },
   "outputs": [],
   "source": [
    "from graph_attribution import tasks\n",
    "from graph_attribution import graphnet_models as gnn_models\n",
    "from graph_attribution import graphnet_techniques as techniques\n",
    "from graph_attribution import datasets\n",
    "from graph_attribution import experiments\n",
    "from graph_attribution import templates\n",
    "from graph_attribution import graphs as graph_utils\n",
    "\n",
    "datasets.DATA_DIR = os.path.join(REPO_DIR, 'data')\n",
    "print(f'Reading data from: {datasets.DATA_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-1hgin_htxk"
   },
   "source": [
    "# Load Experiment data, a task and attribution techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T19:58:18.979633Z",
     "start_time": "2020-11-19T19:58:18.895459Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "83FuJCHIPy9B"
   },
   "outputs": [],
   "source": [
    "print(f'Available tasks: {[t.name for t in tasks.Task]}')\n",
    "print(f'Available model types: {[m.name for m in gnn_models.BlockType]}')\n",
    "print(f'Available ATT techniques: {list(techniques.get_techniques_dict(None,None).keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "        task_type, \n",
    "        block_type \n",
    "):\n",
    "    task_dir = datasets.get_task_dir(task_type)\n",
    "    exp, task, methods = experiments.get_experiment_setup(task_type, block_type)\n",
    "    task_act, task_loss = task.get_nn_activation_fn(), task.get_nn_loss_fn()\n",
    "    graph_utils.print_graphs_tuple(exp.x_train)\n",
    "    \n",
    "    hp = gatt.hparams.get_hparams({'block_type':block_type, 'task_type':task_type})\n",
    "    \n",
    "    model = experiments.GNN(node_size = hp.node_size,\n",
    "               edge_size = hp.edge_size,\n",
    "               global_size = hp.global_size,\n",
    "               y_output_size = task.n_outputs,\n",
    "               block_type = gnn_models.BlockType(hp.block_type),\n",
    "               activation = task_act,\n",
    "               target_type = task.target_type,\n",
    "               n_layers = hp.n_layers)\n",
    "    model(exp.x_train)\n",
    "\n",
    "    optimizer = snt.optimizers.Adam(hp.learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "    opt_one_epoch = gatt.training.make_tf_opt_epoch_fn(exp.x_train, exp.y_train, hp.batch_size, model,\n",
    "                                      optimizer, task_loss)\n",
    "\n",
    "    pbar = tqdm.tqdm(range(hp.epochs))\n",
    "    losses = collections.defaultdict(list)\n",
    "    start_time = time.time()\n",
    "    for _ in pbar:\n",
    "        train_loss = opt_one_epoch(exp.x_train, exp.y_train).numpy()\n",
    "        losses['train'].append(train_loss)\n",
    "        r = model(exp.x_test);\n",
    "        losses['test'].append(task_loss(exp.y_test, model(exp.x_test)[0]).numpy())\n",
    "        pbar.set_postfix({key: values[-1] for key, values in losses.items()})\n",
    "\n",
    "    losses = {key: np.array(values) for key, values in losses.items()}\n",
    "    \n",
    "    graphN = graph_nets.utils_tf.get_num_graphs(exp.x_train)\n",
    "    \n",
    "    if graphN >= 1000:\n",
    "        indexes = np.array(random.sample(range(0, graphN-1), 1000))\n",
    "        indexes.sort()\n",
    "        train_data = graph_utils.get_graphs_tf(exp.x_train, indexes)\n",
    "        print(\"Sampling is done!\")\n",
    "    else:\n",
    "        train_data = exp.x_train\n",
    "    \n",
    "    results = []\n",
    "    for method in tqdm.tqdm(methods.values(), total=len(methods)):\n",
    "        results.append(experiments.generate_result(model, method, task, exp.x_test, exp.y_test, exp.att_test, train_data, 0.01))\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    return pd.DataFrame(results), losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "losses = {}\n",
    "task = ['benzene', 'logic7', 'logic8', 'logic10', 'crippen']\n",
    "block = ['gcn', 'gat', 'mpnn', 'graphnet']\n",
    "n_trials = 5\n",
    "run = range(n_trials)\n",
    "\n",
    "for block, task, run in product(block, task,run):\n",
    "    print((block, task, run))\n",
    "    try:\n",
    "        result, loss = train_and_evaluate(\n",
    "            task_type=task, \n",
    "            block_type=block\n",
    "        )\n",
    "        results[(block, task, run)] = result\n",
    "        losses[(block, task, run)] = loss\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('../data/egsar_results_gcn&gan&mpnn&graphnet(' + str(n_trials) + '_trials).pickle', 'wb') as f:\n",
    "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "private"
   },
   "name": "train_evaluate.ipynb",
   "provenance": [
    {
     "file_id": "/piper/depot/google3/experimental/graph_attribution/graphnets_demo.ipynb",
     "timestamp": 1589329304332
    },
    {
     "file_id": "/piper/depot/google3/experimental/graph_attribution/graphnets_demo.ipynb",
     "timestamp": 1580393977236
    },
    {
     "file_id": "1BfVceP2yhGgdtloEZNy_lR1NP7pjWhez",
     "timestamp": 1579666920169
    },
    {
     "file_id": "1QyHsdvTHd2a4SPXCGtEsd3rL7pT2S6vO",
     "timestamp": 1578435769855
    },
    {
     "file_id": "1kzXpb_wct-EnLPOAvTvRXGCGOiLK7SkP",
     "timestamp": 1578350485474
    },
    {
     "file_id": "/piper/depot/google3/learning/deepmind/tensorflow/graph_nets/tf2/demos/sort.ipynb",
     "timestamp": 1577987457433
    },
    {
     "file_id": "13QaQPnwO8Iq5YjoSraE2Gt_jz3f9e8pc",
     "timestamp": 1571434083446
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/graph_nets/demos/sort.ipynb",
     "timestamp": 1570733816658
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:graph_attribution_egsar]",
   "language": "python",
   "name": "conda-env-graph_attribution_egsar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
